{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmqPQZKZ_aN_"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, DepthwiseConv2D, SeparableConv2D, GlobalAveragePooling2D\n",
        "from keras import optimizers\n",
        "from keras.regularizers import l2\n",
        "import numpy as np\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnyuLqXdA6Bc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class OptimizedCIFAR10CNN:\n",
        "    def __init__(self, lr, train=True):\n",
        "        self.num_classes = 10\n",
        "        self.weight_decay = 1e-4\n",
        "        self.x_shape = [32, 32, 3]\n",
        "        self.lr = lr\n",
        "\n",
        "        self.tiny_vgg = self.build_model()\n",
        "        if train:\n",
        "            self.tiny_vgg, self.history = self.train(self.tiny_vgg)\n",
        "        else:\n",
        "            self.tiny_vgg.load_model('TinyVGG.keras')\n",
        "\n",
        "    def plot_training_history(self, history):\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history['loss'])\n",
        "        plt.plot(history.history['val_loss'])\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def build_model(self):\n",
        "        weight_decay = self.weight_decay\n",
        "\n",
        "        model = keras.Sequential([\n",
        "            # 1st Block\n",
        "            layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay), input_shape=self.x_shape, activation='relu', name=\"conv2d_1\"),\n",
        "            layers.BatchNormalization(name=\"batch_normalization_1\"),\n",
        "            layers.Dropout(0.3, name=\"dropout_1\"),\n",
        "            layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay), activation='relu', name=\"conv2d_2\"),\n",
        "            layers.BatchNormalization(name=\"batch_normalization_2\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2), name=\"max_pooling2d_1\"),\n",
        "\n",
        "            # 2nd Block\n",
        "            layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay), activation='relu', name=\"conv2d_3\"),\n",
        "            layers.BatchNormalization(name=\"batch_normalization_3\"),\n",
        "            layers.Dropout(0.4, name=\"dropout_2\"),\n",
        "            layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay), activation='relu', name=\"conv2d_4\"),\n",
        "            layers.BatchNormalization(name=\"batch_normalization_4\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2), name=\"max_pooling2d_2\"),\n",
        "\n",
        "            # 3rdBlock\n",
        "            layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay), activation='relu', name=\"conv2d_5\"),\n",
        "            layers.BatchNormalization(name=\"batch_normalization_5\"),\n",
        "            layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(weight_decay), activation='relu', name=\"conv2d_6\"),\n",
        "            layers.BatchNormalization(name=\"batch_normalization_6\"),\n",
        "            layers.MaxPooling2D(pool_size=(2, 2), name=\"max_pooling2d_3\"),\n",
        "            layers.Dropout(0.4, name=\"dropout_3\"),\n",
        "\n",
        "            # Fully Connected Layers\n",
        "            layers.Flatten(name=\"flatten_1\"),\n",
        "            layers.Dense(256, kernel_regularizer=keras.regularizers.l2(weight_decay), activation='relu', name=\"dense_1\"),\n",
        "            layers.BatchNormalization(name=\"batch_normalization_7\"),\n",
        "            layers.Dropout(0.5, name=\"dropout_4\"),\n",
        "            layers.Dense(self.num_classes, activation='softmax', name=\"dense_2\")\n",
        "        ])\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "    def normalize(self,X_train,X_test):\n",
        "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
        "        X_train = (X_train-mean)/(std+1e-7)\n",
        "        X_test = (X_test-mean)/(std+1e-7)\n",
        "        return X_train, X_test\n",
        "\n",
        "    def normalize_production(self,x):\n",
        "        mean = 120.707\n",
        "        std = 64.15\n",
        "        return (x-mean)/(std+1e-7)\n",
        "\n",
        "    def predict(self,x,normalize=True,batch_size=50):\n",
        "        if normalize:\n",
        "            x = self.normalize_production(x)\n",
        "        return self.tiny_vgg.predict(x,batch_size)\n",
        "\n",
        "\n",
        "    def train(self, model):\n",
        "        model_name = 'TinyVGG'\n",
        "        batch_size = 128\n",
        "        max_epochs = 150\n",
        "        learning_rate = self.lr\n",
        "\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        x_train, x_test = self.normalize(x_train, x_test)\n",
        "\n",
        "        y_train = keras.utils.to_categorical(y_train, self.num_classes)\n",
        "        y_test = keras.utils.to_categorical(y_test, self.num_classes)\n",
        "\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                      factor=0.7,\n",
        "                                      patience=3,\n",
        "                                      min_lr = 0.00001)\n",
        "\n",
        "\n",
        "        datagen = ImageDataGenerator(\n",
        "              brightness_range=[0.4,1.8],\n",
        "              fill_mode='nearest',\n",
        "              rotation_range=10,\n",
        "              width_shift_range=0.1,\n",
        "              height_shift_range=0.1,\n",
        "              horizontal_flip=True\n",
        "        )\n",
        "        datagen.fit(x_train)\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer=optimizers.legacy.Adam(learning_rate = learning_rate), metrics=['accuracy'])\n",
        "\n",
        "        csv_logger = CSVLogger(f\"{model_name}_history.csv\")\n",
        "\n",
        "        history = model.fit(datagen.flow(x_train, y_train, batch_size = batch_size),\n",
        "                                      steps_per_epoch = x_train.shape[0] // batch_size,\n",
        "                                      epochs = max_epochs,\n",
        "                                      validation_data = (x_test, y_test),\n",
        "                                      callbacks = [csv_logger, reduce_lr],\n",
        "                                      verbose = 2)\n",
        "\n",
        "        # Plot training history\n",
        "        self.plot_training_history(history)\n",
        "\n",
        "        model.save(f\"{model_name}.keras\")\n",
        "        return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSolxLEOOx4T"
      },
      "outputs": [],
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Train the model\n",
        "trained_model = OptimizedCIFAR10CNN(lr = 0.001)\n",
        "\n",
        "tiny_vgg_model = trained_model.tiny_vgg\n",
        "tiny_vgg_history = trained_model.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6JSdyYm-7cv"
      },
      "outputs": [],
      "source": [
        "cifar10_classes = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9yMfekH7McI"
      },
      "outputs": [],
      "source": [
        "y_test_labels = y_test.argmax(axis=1)  # Convert one-hot to labels\n",
        "predictions = tiny_vgg_model.predict(x_test).argmax(axis=1)  # Get predicted labels"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
